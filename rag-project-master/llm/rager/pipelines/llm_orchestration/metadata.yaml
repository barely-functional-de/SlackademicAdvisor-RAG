blocks:
- all_upstream_blocks_executed: true
  color: null
  configuration:
    file_source:
      path: rager/data_loaders/load_llm_zoomcamp_channel_data.py
  downstream_blocks:
  - chunk_llm_data
  executor_config: null
  executor_type: local_python
  has_callback: false
  language: python
  name: load_llm_zoomcamp_channel_data
  retry_config: null
  status: executed
  timeout: null
  type: data_loader
  upstream_blocks: []
  uuid: load_llm_zoomcamp_channel_data
- all_upstream_blocks_executed: true
  color: null
  configuration:
    file_source:
      path: rager/data_loaders/load_faq_data.py
  downstream_blocks:
  - chunk_llm_data
  executor_config: null
  executor_type: local_python
  has_callback: false
  language: python
  name: load_faq_data
  retry_config: null
  status: executed
  timeout: null
  type: data_loader
  upstream_blocks: []
  uuid: load_faq_data
- all_upstream_blocks_executed: true
  color: null
  configuration:
    file_source:
      path: rager/transformers/chunk_llm_data.py
  downstream_blocks:
  - tokenize_llm_data
  executor_config: null
  executor_type: local_python
  has_callback: false
  language: python
  name: chunk_llm_data
  retry_config: null
  status: executed
  timeout: null
  type: transformer
  upstream_blocks:
  - load_faq_data
  - load_llm_zoomcamp_channel_data
  uuid: chunk_llm_data
- all_upstream_blocks_executed: true
  color: null
  configuration:
    file_source:
      path: rager/transformers/tokenize_llm_data.py
  downstream_blocks:
  - embed_llm_data
  executor_config: null
  executor_type: local_python
  has_callback: false
  language: python
  name: tokenize_llm_data
  retry_config: null
  status: executed
  timeout: null
  type: transformer
  upstream_blocks:
  - chunk_llm_data
  uuid: tokenize_llm_data
- all_upstream_blocks_executed: true
  color: null
  configuration:
    file_source:
      path: rager/transformers/embed_llm_data.py
  downstream_blocks: []
  executor_config: null
  executor_type: local_python
  has_callback: false
  language: python
  name: embed_llm_data
  retry_config: null
  status: updated
  timeout: null
  type: transformer
  upstream_blocks:
  - tokenize_llm_data
  uuid: embed_llm_data
cache_block_output_in_memory: false
callbacks: []
concurrency_config: {}
conditionals: []
created_at: '2024-08-03 18:15:26.608283+00:00'
data_integration: null
description: null
executor_config: {}
executor_count: 1
executor_type: null
extensions: {}
name: LLM_Orchestration
notification_config: {}
remote_variables_dir: null
retry_config: {}
run_pipeline_in_one_process: false
settings:
  triggers: null
spark_config: {}
tags: []
type: python
uuid: llm_orchestration
variables:
  data_path: /home/src/data/sample_data/*.json
  faq_data_path: /home/src/data/llm_faq.json
  faq_metadata_file: /home/src/data/metadata/processed_faq_metadata.json
  metadata_file: /home/src/data/metadata/processed_files_metadata.json
variables_dir: /home/src/mage_data/rager
widgets: []
